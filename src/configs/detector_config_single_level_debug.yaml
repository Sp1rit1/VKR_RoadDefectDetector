# src/configs/detector_config_single_level_debug.yaml

# --- Параметры для ОДНОУРОВНЕВОЙ (P4) модели детектора ---
# Цель: Сначала добиться идеального переобучения на ОДНОМ изображении с высокой уверенностью,
#       затем использовать эти параметры (особенно loss_weights) для обучения на всем датасете.

# Эти пути сейчас не используются напрямую этим конфигом для обучения,
# но могут использоваться скриптами инференса/оценки, если они его читают
classifier_model_path: "weights/classifier_trained_model_best.keras"
detector_model_path: "weights/RoadDefectDetector_SingleLevel_P4_SOME_BEST_MODEL.keras" # Заглушка, будет перезаписана

fpn_detector_params: # Оставляем эту структуру, так как твои модули ее ожидают
  model_name_prefix: "RoadDefectDetector_SingleLevel_P4_DebugFocusConfidence" # Новое имя для этого эксперимента
  backbone_name: "MobileNetV2"
  input_shape: [416, 416, 3]
  classes: ["pit", "crack"]
  num_classes: 2

  detector_fpn_levels: ['P4_debug'] # Только один уровень
  detector_fpn_strides:
    P4_debug: 16

  fpn_gt_assignment_scale_ranges:
    P4_debug: [0, 100000] # Все объекты на этот уровень

  detector_fpn_anchor_configs:
    P4_debug:
      num_anchors_this_level: 7 # Твои K-Means якоря для P4
      anchors_wh_normalized:
        - [0.1832, 0.1104]
        - [0.0967, 0.2753]
        - [0.4083, 0.0925]
        - [0.0921, 0.4968]
        - [0.2919, 0.1936]
        - [0.7358, 0.0843]
        - [0.0743, 0.8969]

  head_config:
    head_depth: 2
    head_conv_filters: 256
    leaky_relu_alpha: 0.1
    l2_regularization: 0.00001 # <<<--- ОТКЛЮЧАЕМ L2 для теста на одном изображении, чтобы не мешало переобучению. Потом можно вернуть 0.00001 для полного.

# --- Параметры Обучения (сначала для теста на одном изображении, потом адаптируем для полного) ---
continue_from_checkpoint: false
path_to_checkpoint: null

unfreeze_backbone: false              # Backbone ЗАМОРОЖЕН
finetune_keep_bn_frozen: true
unfreeze_backbone_layers_from_end: 0

batch_size: 8                         # <<<--- КРИТИЧНО: 1 для обучения на одном изображении
epochs_for_debug: 300                 # Используется в debug_single_level_train_on_one_image.py как NUM_ITERATIONS
                                      # Для train_detector_single_level_debug.py будет использоваться "epochs" ниже.
epochs: 150                           # Для полноценного обучения на всем датасете

initial_learning_rate: 0.0001          # <<<--- ВЫСОКИЙ LR для быстрого переобучения на ОДНОМ изображении.
                                      # Для полного датасета мы потом поставим 0.0001.
# finetune_learning_rate не используется

# Параметры Callbacks (для train_detector_single_level_debug.py)
early_stopping_patience: 20
reduce_lr_patience: 7
reduce_lr_factor: 0.2
min_lr_on_plateau: 0.0000005

use_augmentation: true # <<<--- ОТКЛЮЧАЕМ АУГМЕНТАЦИЮ для теста на одном изображении. Потом true для полного.

# --- Параметры Функции Потерь (ФОКУС НА OBJECTNESS) ---
loss_weights:
  coordinates: 0.1       # Временно снижаем важность точных координат
  objectness: 10.0     # <<< ОЧЕНЬ ВЫСОКИЙ ВЕС для позитивных якорей
  no_object: 1.25         # <<< ОЧЕНЬ НИЗКИЙ ВЕС для фона (чтобы не подавлять objectness)
  classification: 1.5

focal_loss_objectness_params:
  use_focal_loss: true # <<<--- ВРЕМЕННО ОТКЛЮЧАЕМ Focal Loss. Сначала добьемся работы с BCE и весами. Потом можно вернуть.
  alpha: 0.5
  gamma: 2.0

# --- Параметры для Инференса ---
predict_params:
  confidence_threshold: 0.5 # Начнем с низкого для отладки
  iou_threshold: 0.3
  max_detections: 10