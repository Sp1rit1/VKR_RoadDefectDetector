# src/configs/detector_config_v3_standard.yaml

# --- Основные параметры модели и датасета ---
model_name: "DetectorV3Standard" # Название нашей новой модели детектора
description: "Standard object detection model with EfficientNetB0, FPN, and RetinaNet-like heads"

# Пути к подготовленному датасету для детектора (относительно корня проекта)
# Предполагаем, что структура папок train/images, train/Annotations, val/images, val/Annotations
# уже создана с помощью create_data_splits.py и prepare_classifier_dataset.py (для детектора)
dataset_path: "data/Detector_Dataset_Ready"
train_images_subdir: "train/images"
train_annotations_subdir: "train/Annotations"
val_images_subdir: "validation/images"
val_annotations_subdir: "validation/Annotations"

# Параметры изображений
input_shape: [512, 512, 3] # Входной размер изображений для детектора [высота, ширина, каналы]. Выбираем побольше для детекции.
image_normalization_method: "imagenet" # Метод нормализации изображений (e.g., "imagenet" для EfficientNet)

# Параметры классов
num_classes: 2 # Количество классов объектов для детекции (pit, crack)
class_names: ["pit", "crack"] # Имена классов в правильном порядке

# --- Параметры якорей (Anchors) ---
# Эти значения должны быть рассчитаны с помощью скрипта calculate_anchors.py
# для каждого уровня FPN (P3, P4, P5), который соответствует strides 8, 16, 32.
# num_anchors_per_level должно быть равно (количество scales) * (количество ratios)
anchor_scales:
  P3: # Выбрано K=6 якорей для P3 (Stride 8). AvgIoU: 0.6602
    - [0.047552, 0.038220] # Примерно 24.35x19.57 px
    - [0.095647, 0.056186] # Примерно 48.97x28.77 px
    - [0.052871, 0.107558] # Примерно 27.07x55.07 px
    - [0.150611, 0.045594] # Примерно 77.11x23.34 px
    - [0.040382, 0.188408] # Примерно 20.68x96.46 px
    - [0.254573, 0.032730] # Примерно 130.34x16.76 px
  P4: # Выбрано K=8 якорей для P4 (Stride 16). AvgIoU: 0.6621
    - [0.171035, 0.120275] # Примерно 87.57x61.58 px
    - [0.088787, 0.283158] # Примерно 45.46x144.98 px
    - [0.328646, 0.084558] # Примерно 168.27x43.29 px
    - [0.098792, 0.506954] # Примерно 50.58x259.56 px
    - [0.515734, 0.110820] # Примерно 264.06x56.74 px
    - [0.291473, 0.226871] # Примерно 149.23x116.16 px
    - [0.822996, 0.086319] # Примерно 421.37x44.20 px
    - [0.079186, 0.910822] # Примерно 40.54x466.34 px
  P5: # Выбрано K=8 якорей для P5 (Stride 32). AvgIoU: 0.7446
    - [0.409999, 0.342899] # Примерно 209.92x175.56 px
    - [0.275738, 0.632459] # Примерно 141.18x323.82 px
    - [0.632889, 0.287996] # Примерно 324.04x147.45 px
    - [0.959507, 0.190531] # Примерно 491.27x97.55 px
    - [0.239537, 0.923317] # Примерно 122.64x472.74 px
    - [0.600015, 0.558364] # Примерно 307.21x285.88 px
    - [0.918102, 0.485906] # Примерно 470.07x248.78 px
    - [0.885235, 0.769869] # Примерно 453.24x394.17 px

anchor_ratios:
  P3: [0.5, 1.0, 2.0]
  P4: [0.5, 1.0, 2.0]
  P5: [0.5, 1.0, 2.0]

# Количество якорей в каждой ячейке сетки для каждого уровня FPN.
# Должно быть равно (количество scales для уровня) * (количество ratios для уровня).
num_anchors_per_level:
  P3: 18 # Если K=6 scales * 3 ratios = 18
  P4: 24 # Если K=8 scales * 3 ratios = 24
  P5: 24 # Если K=8 scales * 3 ratios = 24

anchor_calc_k_range: [3, 4, 5, 6, 7, 8, 9] # Пример: анализ от 3 до 9 якорей

# Папка для сохранения графиков анализа якорей (относительно корня проекта)
anchor_analysis_output_dir: "graphs/anchor_analysis"

# --- Параметры FPN (Feature Pyramid Network) ---
fpn_filters: 256 # Количество фильтров в сверточных слоях FPN и голов

# --- Параметры назначения GT (Ground Truth Assignment) ---
# Диапазоны площади GT объектов для назначения на каждый уровень FPN (P3, P4, P5).
# Формат: [[min_area_P3, max_area_P3], [min_area_P4, max_area_P4], [min_area_P5, max_area_P5]]
# Используются площади в пикселях. float('inf') означает бесконечность.
# Примерные диапазоны основаны на типичных размерах объектов, детектируемых на уровнях с разным шагом (stride).
# P3 (stride 8) для мелких, P4 (stride 16) для средних, P5 (stride 32) для крупных.
fpn_gt_assignment_area_ranges:
  - [0.0, 0.01]      # Объекты с норм. площадью < 0.01 -> P3 (stride 8). Начнем с такого порога.
  - [0.01, 0.1]      # Объекты с 0.01 <= норм. площадь < 0.1 -> P4 (stride 16). Начнем с такого порога.
  - [0.1, 1.0]       # Объекты с норм. площадью >= 0.1 -> P5 (stride 32). До 1.0

# Пороги IoU для назначения якорей к GT
anchor_positive_iou_threshold: 0.5 # IoU > 0.5 -> позитивный якорь
anchor_ignore_iou_threshold: 0.4   # 0.4 <= IoU < 0.5 -> игнорируемый якорь
# Якоря с IoU < 0.4 считаются негативными (фоном)

# --- Параметры функции потерь ---
# Веса для компонент потерь
loss_weights:
  classification: 1.0
  box_regression: 1.5 # Вес регрессии часто немного больше классификации

# Параметры Focal Loss для классификации
focal_loss_alpha: 0.25 # Балансирующий фактор. Уменьшает вклад легко классифицируемых негативов. 0.25 - стандартное значение.
focal_loss_gamma: 2.0  # Параметр фокусировки. Увеличивает штраф за ошибки на сложных примерах. 2.0 - стандартное значение.

# Параметры Box Regression Loss
box_loss_type: "huber" # Тип функции потери для рамок: "huber" или "ciou"
huber_loss_delta: 1.0  # Параметр delta для Huber Loss

# --- Параметры обучения ---
optimizer: "AdamW" # Оптимизатор. AdamW - хорошо работает с регуляризацией весов.
initial_learning_rate: 0.0001 # Начальная скорость обучения (часто ниже для детекции, особенно с предобученным backbone)

# Планировщик скорости обучения (LR Scheduler)
lr_schedule: "cosine_decay" # "cosine_decay" или "step_decay" или "none"
warmup_epochs: 5 # Количество эпох для линейного увеличения LR (от маленького значения до initial_learning_rate)
cosine_decay_epochs: 150 # Общее количество эпох для косинусного затухания после warmup (или общее количество эпох тренировки)
# step_decay_params: # Если используется step_decay
#   steps_per_epoch: 1000 # Количество шагов в эпохе (для расчета шагов снижения)
#   drop_rate: 0.5
#   epochs_drop: 30

epochs_phase1: 50 # Количество эпох обучения с замороженным backbone
epochs_phase2: 150 # Количество эпох fine-tuning с размороженным backbone (общая длительность фазы 2)
batch_size: 8 # Количество изображений в батче

# Использовать ли аугментацию данных во время тренировки
use_augmentation: true

# Пути для сохранения логов и весов (относительно корня проекта или базовых директорий из base_config.yaml)
# Можно использовать метку времени или другие идентификаторы для организации запусков
log_dir: "logs/detector_v3_standard"
saved_model_dir: "weights/detector_v3_standard" # Папка для сохранения чекпоинтов и лучшей модели
best_model_filename: "best_model.keras" # Имя файла для сохранения лучшей модели

# --- Параметры оценки (Evaluation) ---
# Пороги для Non-Maximum Suppression (NMS) и фильтрации предсказаний во время оценки
eval_conf_threshold: 0.5 # Минимальная уверенность для рассмотрения предсказания
eval_iou_threshold: 0.45 # Порог IoU для NMS

# --- Параметры инференса (Prediction) ---
# Пороги для NMS и фильтрации предсказаний во время инференса
# Эти могут отличаться от eval_conf_threshold/eval_iou_threshold,
# например, для демонстрации можно использовать более низкий порог уверенности.
predict_conf_threshold: 0.3
predict_iou_threshold: 0.4