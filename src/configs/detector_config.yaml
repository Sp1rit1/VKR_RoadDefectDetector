# src/configs/detector_config.yaml

# --- Параметры для FPN модели детектора ---
fpn_detector_params:
  model_name_prefix: "RoadDefectDetector_v2_FPN" # Используется для имен логов/моделей
  backbone_name: "MobileNetV2"
  backbone_layer_name_in_model: "Backbone_MobileNetV2_FPN_Features"
  input_shape: [416, 416, 3]
  classes: ["pit", "crack"] # pit:0, crack:1
  num_classes: 2

  detector_fpn_levels: ['P3', 'P4', 'P5']
  detector_fpn_strides: # Важно, чтобы эти страйды соответствовали тем слоям, что берутся из backbone
    P3: 8
    P4: 16
    P5: 32

  fpn_gt_assignment_scale_ranges: # Диапазоны для назначения GT (в пикселях оригинального изображения)
    P3: [0, 64]    # Пример: для мелких объектов (до 80x80px по большей стороне или sqrt(area))
    P4: [64, 128]  # Пример: для средних объектов
    P5: [128, 10000] # Пример: для крупных объектов (10000 как "бесконечность")
    # Эти диапазоны НУЖНО будет подобрать на основе АНАЛИЗА РАСПРЕДЕЛЕНИЯ РАЗМЕРОВ ваших GT объектов.
    # Сейчас это просто примерные значения. Цель - чтобы каждый уровень FPN специализировался на своем масштабе.

  detector_fpn_anchor_configs: # Твои K-Means якоря - ОТЛИЧНО!
    P3:
      num_anchors_this_level: 6
      anchors_wh_normalized:
        - [0.0477, 0.0377]
        - [0.0960, 0.0561]
        - [0.0527, 0.1068]
        - [0.1509, 0.0456]
        - [0.0404, 0.1884]
        - [0.2546, 0.0327]
    P4:
      num_anchors_this_level: 7
      anchors_wh_normalized:
        - [0.1832, 0.1104]
        - [0.0967, 0.2753]
        - [0.4083, 0.0925]
        - [0.0921, 0.4968]
        - [0.2919, 0.1936]
        - [0.7358, 0.0843]
        - [0.0743, 0.8969]
    P5:
      num_anchors_this_level: 6
      anchors_wh_normalized:
        - [0.4390, 0.2989]
        - [0.2827, 0.6137]
        - [0.9204, 0.2119]
        - [0.2276, 0.9227]
        - [0.6332, 0.4624]
        - [0.9001, 0.6784]

  head_config:
    fpn_filters: 256
    head_depth: 2                # Оставим 2 для начала. Если недообучается, можно увеличить до 3.
    head_conv_filters: 256
    leaky_relu_alpha: 0.1
    l2_regularization: 0.00001   # <<< ДОБАВИМ ОЧЕНЬ МАЛЕНЬКУЮ L2 РЕГУЛЯРИЗАЦИЮ (можно начать с null, если переобучения нет)

# --- Общие Параметры Обучения (для текущего запуска FPN) ---
continue_from_checkpoint: false       # Начинаем обучение FPN с нуля
path_to_checkpoint: null

unfreeze_backbone: false              # ЭТАП 1: Обучаем "головы" FPN с замороженным backbone
finetune_keep_bn_frozen: true         # Важно для последующего fine-tuning'а
unfreeze_backbone_layers_from_end: 20 # Количество слоев для разморозки на ЭТАПЕ 2 (fine-tuning)

batch_size: 1                         # <<< ПОПРОБУЕМ 8 (если VRAM позволяет, если нет - 4)
epochs: 500                           # Общее количество эпох (EarlyStopping проконтролирует)

initial_learning_rate: 0.001       # (5e-4) <<< УВЕЛИЧИМ немного для начального обучения FPN-голов.
                                      # 1e-4 могло быть слишком медленно. Будем следить за стабильностью.
                                      # Если будет нестабильно, вернем 1e-4.
finetune_learning_rate: 0.00001      # (1e-5) Для этапа fine-tuning'а (ЭТАП 2)

early_stopping_patience: 25           # Увеличим немного терпение
reduce_lr_patience: 10                # Увеличим немного терпение
reduce_lr_factor: 0.2
min_lr_on_plateau: 0.0000005 # (5e-8)

use_augmentation: true                # Обязательно для большого датасета

debug_callback_log_freq: 1  # <<<--- УСТАНОВИ В 1
debug_callback_num_samples: 1 # (или сколько ты хочешь видеть)
debug_callback_enable_visualization: false

# --- Параметры Функции Потерь ---
loss_weights:
  coordinates: 1.5                    # Вес для координат
  objectness: 5.0                     # <<< ЗНАЧИТЕЛЬНО УВЕЛИЧИВАЕМ, чтобы поднять уверенность
  no_object: 0.1                      # <<< Увеличиваем, чтобы сбалансировать objectness и штрафовать фон
  classification: 2.0                # Увеличиваем, чтобы классификация была точнее

focal_loss_objectness_params:
  use_focal_loss: false                # <<< ОСТАВЛЯЕМ TRUE, это должно помочь с уверенностью
  alpha: 0.25                         # Стандартное значение
  gamma: 2.0                          # Стандартное значение

