# src/configs/detector_config.yaml

# --- Общие Параметры Модели Детектора ---
model_base_name: "RoadDefectDetector_v1"    # Базовое имя для файлов моделей и логов
backbone_name: "MobileNetV2"                # Какую pre-trained модель использовать как основу
input_shape: [416, 416, 3]               # Входной размер изображений для детектора
backbone_layer_name_in_model: "Backbone_MobileNetV2" # Имя слоя backbone в модели (проверь model.summary())

# Параметры для "головы" предсказаний (используются в build_object_detector_v1_enhanced)
head_body_conv_filters: 256                 # Фильтры в первом слое "тела" головы
head_body_depth: 2                          # Количество Conv-BN-LeakyReLU блоков в "теле" головы
leaky_relu_alpha: 0.1                       # Alpha для LeakyReLU
l2_regularization: 0.0005                   # Коэффициент L2 регуляризации

# --- Параметры Классов и Якорей ---
classes: ["pit", "crack"]                  # pit:0, crack:1
num_classes: 2
# ЗАМЕНИ ЭТИ ЯКОРЯ на те, что получишь от K-Means кластеризации на твоем полном датасете!
anchors_wh_normalized:
  - [0.1326, 0.0919]
  - [0.1059, 0.3704]
  - [0.3600, 0.1728]
  - [0.1484, 0.8278]
  - [0.7600, 0.2444]
  - [0.6420, 0.6129]
num_anchors_per_location: 6

# --- Режим и Параметры Обучения ---
# Устанавливаем режим для FINE-TUNING'а
continue_from_checkpoint: true        # <<<--- Устанавливаем в true, чтобы загрузить модель
path_to_checkpoint: "detector_v1_best_overall.keras" # <<<--- ЗАМЕНИ НА ИМЯ ТВОЕЙ ЛУЧШЕЙ МОДЕЛИ
                                       # (например, detector_v1_best_overall.keras или как она у тебя называется
                                       # после начального обучения с замороженным backbone)

unfreeze_backbone: true               # <<<--- Устанавливаем в true, чтобы разморозить backbone

# Параметры для разморозки backbone (если unfreeze_backbone: true)
# 0 - разморозить весь backbone. >0 - количество слоев с КОНЦА backbone, которые будут обучаться.
unfreeze_backbone_layers_from_end: 0  # <<<--- Размораживаем весь backbone

# Общие параметры обучения (эпохи для текущего сеанса)
batch_size: 2                         # Для fine-tuning'а часто уменьшают batch_size из-за увеличения потребления памяти
epochs: 100                            # Количество эпох для fine-tuning'а (может быть меньше, чем для начального)

# Learning Rates
initial_learning_rate: 0.0001         # Этот LR будет использован, если continue_from_checkpoint=false
finetune_learning_rate: 0.00001     # (1e-5) <<<--- Этот LR будет использован, т.к. unfreeze_backbone: true

# Параметры Callbacks
early_stopping_patience: 15           # Терпение для EarlyStopping при fine-tuning'е (можно сделать чуть меньше)
reduce_lr_patience: 5                # Терпение для ReduceLROnPlateau при fine-tuning'е
reduce_lr_factor: 0.2
min_lr_on_plateau: 0.0000001 # (1e-7) Можно еще ниже для fine-tuning'а

# Аугментация
use_augmentation: false # <<<--- ЧАСТО ПРИ FINE-TUNING'Е АУГМЕНТАЦИЮ ДЕЛАЮТ МЕНЕЕ АГРЕССИВНОЙ ИЛИ ВЫКЛЮЧАЮТ
                        # Если хочешь использовать, установи в true и убедись, что
                        # train_detector.py это учитывает для fine-tuning'а
                        # (в текущей версии train_detector.py флаг current_use_augmentation
                        # будет равен этому значению, если мы не в initial_train без unfreeze)

# --- Параметры Функции Потерь ---
loss_weights:
  coordinates: 1.5
  objectness: 1.0
  no_object: 0.7
  classification: 1.0

# --- Параметры для Инференса ---
predict_params:
  confidence_threshold: 0.25 # Подбери после fine-tuning'а
  iou_threshold: 0.45        # Подбери после fine-tuning'а
  max_detections: 100